{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "7628432b",
      "metadata": {},
      "source": [
        "# [SemEval 2023 Task 1](https://raganato.github.io/vwsd/)\n",
        "\n",
        "[By Abdullah Alshadadi (Srking501)](https://github.com/Srking501)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-03-17 00:01:39.897118: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-17 00:01:40.440663: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory\n",
            "2023-03-17 00:01:40.440706: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory\n",
            "2023-03-17 00:01:40.440711: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import keras\n",
        "import random\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "189967aa",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c9945c50",
      "metadata": {},
      "outputs": [],
      "source": [
        "# to access google drive folder\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive') # When you run this you'll be prompted for a token - follow the link to generate this.\n",
        "# #        \"/content/drive/MyDrive/...path/to/dir\n",
        "# path = \"/content/drive/MyDrive/semeval-2023/task-1/\"\n",
        "# path = \"/content/drive/MyDrive/data/\"\n",
        "\n",
        "# Comment this out if you are using Google Colab, otherwise just change to local directory where the data is located\n",
        "path = \"./data/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6cbda6ac",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/home/srking501/Desktop/Projects/semeval-2023-task1'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "41358c9d",
      "metadata": {},
      "source": [
        "❗❗❗Retrieve the data from [SemEval-2023 Task-1 page](https://raganato.github.io/vwsd/), specifically the [\"[TRAIN+TRIAL]\" data](https://drive.google.com/file/d/1byX4wpe1UjyCVyYrT04sW17NnycKAK7N/view), and put it into `data/` directory❗❗❗"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a69f9e46",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Data already unzipped]\n"
          ]
        }
      ],
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "try:\n",
        "    if os.path.isdir(path + \"semeval-2023-task-1-V-WSD-train-v1\") == False:\n",
        "        with ZipFile(path + \"semeval-2023-task-1-V-WSD-train-v1.zip\", \"r\") as zip:\n",
        "            print(\"Unzipping data...\")\n",
        "            zip.extractall(\"data/\")\n",
        "            print(\"Finished.\")\n",
        "    else:\n",
        "        print(\"[Data already unzipped]\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file semeval-2023-task-1-V-WSD-train-v1.zip is not found in path:\\n\"\n",
        "          f\"{path}\\n\")\n",
        "    print(f\"The contents of {path}:\\n\"\n",
        "          f\"{os.listdir(path)}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "b426d440",
      "metadata": {},
      "source": [
        "To check if we are in the right directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8c001267",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['result_senses.txt',\n",
              " 'semeval-2023-task-1-V-WSD-train-v1',\n",
              " 'captions_train_clean_complete.csv',\n",
              " 'README.md',\n",
              " 'wordnet(individual tokens).csv']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.listdir(path)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "c71d11be",
      "metadata": {},
      "source": [
        "Using `train_v1/` data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "dbd6ef20",
      "metadata": {},
      "outputs": [],
      "source": [
        "path_to_data = path + \"semeval-2023-task-1-V-WSD-train-v1/\"\n",
        "data_labels = pd.read_csv(path_to_data + \"train_v1/train.data.v1.txt\", \n",
        "                sep = \"\\t\", \n",
        "                names = [\"target_word\", \"full_phrase\"] + \n",
        "                [\"image_%d\"%index for index in range(10)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8413dcb7",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target_word</th>\n",
              "      <th>full_phrase</th>\n",
              "      <th>image_0</th>\n",
              "      <th>image_1</th>\n",
              "      <th>image_2</th>\n",
              "      <th>image_3</th>\n",
              "      <th>image_4</th>\n",
              "      <th>image_5</th>\n",
              "      <th>image_6</th>\n",
              "      <th>image_7</th>\n",
              "      <th>image_8</th>\n",
              "      <th>image_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moorhen</td>\n",
              "      <td>moorhen swamphen</td>\n",
              "      <td>image.3.jpg</td>\n",
              "      <td>image.8.jpg</td>\n",
              "      <td>image.4.jpg</td>\n",
              "      <td>image.1.jpg</td>\n",
              "      <td>image.2.jpg</td>\n",
              "      <td>image.0.jpg</td>\n",
              "      <td>image.5.jpg</td>\n",
              "      <td>image.6.jpg</td>\n",
              "      <td>image.7.jpg</td>\n",
              "      <td>image.9.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>serinus</td>\n",
              "      <td>serinus genus</td>\n",
              "      <td>image.3.jpg</td>\n",
              "      <td>image.23.jpg</td>\n",
              "      <td>image.4.jpg</td>\n",
              "      <td>image.1.jpg</td>\n",
              "      <td>image.2.jpg</td>\n",
              "      <td>image.20.jpg</td>\n",
              "      <td>image.5.jpg</td>\n",
              "      <td>image.24.jpg</td>\n",
              "      <td>image.22.jpg</td>\n",
              "      <td>image.21.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pegmatite</td>\n",
              "      <td>pegmatite igneous</td>\n",
              "      <td>image.41.jpg</td>\n",
              "      <td>image.39.jpg</td>\n",
              "      <td>image.42.jpg</td>\n",
              "      <td>image.43.jpg</td>\n",
              "      <td>image.40.jpg</td>\n",
              "      <td>image.44.jpg</td>\n",
              "      <td>image.37.jpg</td>\n",
              "      <td>image.38.jpg</td>\n",
              "      <td>image.36.jpg</td>\n",
              "      <td>image.35.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bangalores</td>\n",
              "      <td>bangalores torpedo</td>\n",
              "      <td>image.58.jpg</td>\n",
              "      <td>image.59.jpg</td>\n",
              "      <td>image.64.jpg</td>\n",
              "      <td>image.57.jpg</td>\n",
              "      <td>image.55.jpg</td>\n",
              "      <td>image.56.jpg</td>\n",
              "      <td>image.62.jpg</td>\n",
              "      <td>image.63.jpg</td>\n",
              "      <td>image.61.jpg</td>\n",
              "      <td>image.60.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bonxie</td>\n",
              "      <td>bonxie skua</td>\n",
              "      <td>image.3.jpg</td>\n",
              "      <td>image.77.jpg</td>\n",
              "      <td>image.78.jpg</td>\n",
              "      <td>image.4.jpg</td>\n",
              "      <td>image.1.jpg</td>\n",
              "      <td>image.2.jpg</td>\n",
              "      <td>image.5.jpg</td>\n",
              "      <td>image.79.jpg</td>\n",
              "      <td>image.76.jpg</td>\n",
              "      <td>image.75.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  target_word         full_phrase       image_0       image_1       image_2  \\\n",
              "0     moorhen    moorhen swamphen   image.3.jpg   image.8.jpg   image.4.jpg   \n",
              "1     serinus       serinus genus   image.3.jpg  image.23.jpg   image.4.jpg   \n",
              "2   pegmatite   pegmatite igneous  image.41.jpg  image.39.jpg  image.42.jpg   \n",
              "3  bangalores  bangalores torpedo  image.58.jpg  image.59.jpg  image.64.jpg   \n",
              "4      bonxie         bonxie skua   image.3.jpg  image.77.jpg  image.78.jpg   \n",
              "\n",
              "        image_3       image_4       image_5       image_6       image_7  \\\n",
              "0   image.1.jpg   image.2.jpg   image.0.jpg   image.5.jpg   image.6.jpg   \n",
              "1   image.1.jpg   image.2.jpg  image.20.jpg   image.5.jpg  image.24.jpg   \n",
              "2  image.43.jpg  image.40.jpg  image.44.jpg  image.37.jpg  image.38.jpg   \n",
              "3  image.57.jpg  image.55.jpg  image.56.jpg  image.62.jpg  image.63.jpg   \n",
              "4   image.4.jpg   image.1.jpg   image.2.jpg   image.5.jpg  image.79.jpg   \n",
              "\n",
              "        image_8       image_9  \n",
              "0   image.7.jpg   image.9.jpg  \n",
              "1  image.22.jpg  image.21.jpg  \n",
              "2  image.36.jpg  image.35.jpg  \n",
              "3  image.61.jpg  image.60.jpg  \n",
              "4  image.76.jpg  image.75.jpg  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_labels.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6a08dbce",
      "metadata": {},
      "outputs": [],
      "source": [
        "gold_labels = pd.read_csv(path_to_data + \"train_v1/train.gold.v1.txt\", \n",
        "                    names = [\"gold_images\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "c468a123",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gold_images</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>image.0.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>image.20.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>image.35.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>image.55.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>image.75.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    gold_images\n",
              "0   image.0.jpg\n",
              "1  image.20.jpg\n",
              "2  image.35.jpg\n",
              "3  image.55.jpg\n",
              "4  image.75.jpg"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gold_labels.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "19764c2c",
      "metadata": {},
      "source": [
        "Image Caption Data and WordNet senses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "1931fd43",
      "metadata": {},
      "outputs": [],
      "source": [
        "caption_data_labels = pd.read_csv(path + \"captions_train_clean_complete.csv\")\n",
        "wordnet_senses_labels = pd.read_csv(path + \"wordnet(individual tokens).csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1abd655d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File Name</th>\n",
              "      <th>Generated Caption</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>image.0.jpg</td>\n",
              "      <td>a black and white bird is standing in the air</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>image.1.jpg</td>\n",
              "      <td>a man with a red hat is standing in front of a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>image.10.jpg</td>\n",
              "      <td>a man is standing in a large white and white a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>image.100.jpg</td>\n",
              "      <td>a man and a woman are playing with a toy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>image.1000.jpg</td>\n",
              "      <td>a person is riding a dirt path in a wooded area</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        File Name                                  Generated Caption\n",
              "0     image.0.jpg      a black and white bird is standing in the air\n",
              "1     image.1.jpg  a man with a red hat is standing in front of a...\n",
              "2    image.10.jpg  a man is standing in a large white and white a...\n",
              "3   image.100.jpg           a man and a woman are playing with a toy\n",
              "4  image.1000.jpg    a person is riding a dirt path in a wooded area"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "caption_data_labels.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "b751834b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Complex_word</th>\n",
              "      <th>senses</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moorhen swamphen</td>\n",
              "      <td>black gallinule that inhabits ponds and lakes ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>serinus genus</td>\n",
              "      <td>Old World finches; e.g. canaries and serins or...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pegmatite igneous</td>\n",
              "      <td>produced under conditions involving intense he...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bangalore torpedo</td>\n",
              "      <td>an industrial city in south central India (wes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bonxie skua</td>\n",
              "      <td>gull-like jaeger of northern seas or gull-like...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Complex_word                                             senses\n",
              "0   moorhen swamphen  black gallinule that inhabits ponds and lakes ...\n",
              "1      serinus genus  Old World finches; e.g. canaries and serins or...\n",
              "2  pegmatite igneous  produced under conditions involving intense he...\n",
              "3  bangalore torpedo  an industrial city in south central India (wes...\n",
              "4        bonxie skua  gull-like jaeger of northern seas or gull-like..."
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wordnet_senses_labels.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "7fa11a7b",
      "metadata": {},
      "source": [
        "## Creating the main `dataset`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "22887baf",
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = data_labels.join(gold_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "d7834333",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target_word</th>\n",
              "      <th>full_phrase</th>\n",
              "      <th>image_0</th>\n",
              "      <th>image_1</th>\n",
              "      <th>image_2</th>\n",
              "      <th>image_3</th>\n",
              "      <th>image_4</th>\n",
              "      <th>image_5</th>\n",
              "      <th>image_6</th>\n",
              "      <th>image_7</th>\n",
              "      <th>image_8</th>\n",
              "      <th>image_9</th>\n",
              "      <th>gold_images</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moorhen</td>\n",
              "      <td>moorhen swamphen</td>\n",
              "      <td>image.3.jpg</td>\n",
              "      <td>image.8.jpg</td>\n",
              "      <td>image.4.jpg</td>\n",
              "      <td>image.1.jpg</td>\n",
              "      <td>image.2.jpg</td>\n",
              "      <td>image.0.jpg</td>\n",
              "      <td>image.5.jpg</td>\n",
              "      <td>image.6.jpg</td>\n",
              "      <td>image.7.jpg</td>\n",
              "      <td>image.9.jpg</td>\n",
              "      <td>image.0.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>serinus</td>\n",
              "      <td>serinus genus</td>\n",
              "      <td>image.3.jpg</td>\n",
              "      <td>image.23.jpg</td>\n",
              "      <td>image.4.jpg</td>\n",
              "      <td>image.1.jpg</td>\n",
              "      <td>image.2.jpg</td>\n",
              "      <td>image.20.jpg</td>\n",
              "      <td>image.5.jpg</td>\n",
              "      <td>image.24.jpg</td>\n",
              "      <td>image.22.jpg</td>\n",
              "      <td>image.21.jpg</td>\n",
              "      <td>image.20.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pegmatite</td>\n",
              "      <td>pegmatite igneous</td>\n",
              "      <td>image.41.jpg</td>\n",
              "      <td>image.39.jpg</td>\n",
              "      <td>image.42.jpg</td>\n",
              "      <td>image.43.jpg</td>\n",
              "      <td>image.40.jpg</td>\n",
              "      <td>image.44.jpg</td>\n",
              "      <td>image.37.jpg</td>\n",
              "      <td>image.38.jpg</td>\n",
              "      <td>image.36.jpg</td>\n",
              "      <td>image.35.jpg</td>\n",
              "      <td>image.35.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bangalores</td>\n",
              "      <td>bangalores torpedo</td>\n",
              "      <td>image.58.jpg</td>\n",
              "      <td>image.59.jpg</td>\n",
              "      <td>image.64.jpg</td>\n",
              "      <td>image.57.jpg</td>\n",
              "      <td>image.55.jpg</td>\n",
              "      <td>image.56.jpg</td>\n",
              "      <td>image.62.jpg</td>\n",
              "      <td>image.63.jpg</td>\n",
              "      <td>image.61.jpg</td>\n",
              "      <td>image.60.jpg</td>\n",
              "      <td>image.55.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bonxie</td>\n",
              "      <td>bonxie skua</td>\n",
              "      <td>image.3.jpg</td>\n",
              "      <td>image.77.jpg</td>\n",
              "      <td>image.78.jpg</td>\n",
              "      <td>image.4.jpg</td>\n",
              "      <td>image.1.jpg</td>\n",
              "      <td>image.2.jpg</td>\n",
              "      <td>image.5.jpg</td>\n",
              "      <td>image.79.jpg</td>\n",
              "      <td>image.76.jpg</td>\n",
              "      <td>image.75.jpg</td>\n",
              "      <td>image.75.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  target_word         full_phrase       image_0       image_1       image_2  \\\n",
              "0     moorhen    moorhen swamphen   image.3.jpg   image.8.jpg   image.4.jpg   \n",
              "1     serinus       serinus genus   image.3.jpg  image.23.jpg   image.4.jpg   \n",
              "2   pegmatite   pegmatite igneous  image.41.jpg  image.39.jpg  image.42.jpg   \n",
              "3  bangalores  bangalores torpedo  image.58.jpg  image.59.jpg  image.64.jpg   \n",
              "4      bonxie         bonxie skua   image.3.jpg  image.77.jpg  image.78.jpg   \n",
              "\n",
              "        image_3       image_4       image_5       image_6       image_7  \\\n",
              "0   image.1.jpg   image.2.jpg   image.0.jpg   image.5.jpg   image.6.jpg   \n",
              "1   image.1.jpg   image.2.jpg  image.20.jpg   image.5.jpg  image.24.jpg   \n",
              "2  image.43.jpg  image.40.jpg  image.44.jpg  image.37.jpg  image.38.jpg   \n",
              "3  image.57.jpg  image.55.jpg  image.56.jpg  image.62.jpg  image.63.jpg   \n",
              "4   image.4.jpg   image.1.jpg   image.2.jpg   image.5.jpg  image.79.jpg   \n",
              "\n",
              "        image_8       image_9   gold_images  \n",
              "0   image.7.jpg   image.9.jpg   image.0.jpg  \n",
              "1  image.22.jpg  image.21.jpg  image.20.jpg  \n",
              "2  image.36.jpg  image.35.jpg  image.35.jpg  \n",
              "3  image.61.jpg  image.60.jpg  image.55.jpg  \n",
              "4  image.76.jpg  image.75.jpg  image.75.jpg  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "3dd2f653",
      "metadata": {},
      "source": [
        "The only important dataframes are `caption_data_labels_renamed` and the newly merged `wordnet_senses_labels_renamed` into the main `dataset` dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "a0e28b6a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# renaming columns to match the `data_labels` dataframe and \n",
        "# to fit one standard format \n",
        "# (following the python naming convention - \n",
        "# https://peps.python.org/pep-0008/#naming-conventions)\n",
        "#\n",
        "caption_data_labels_renamed = caption_data_labels.rename(columns={\n",
        "    \"File Name\": \"images\",\n",
        "    \"Generated Caption\": \"generated_caption\"\n",
        "    })\n",
        "wordnet_senses_labels_renamed = wordnet_senses_labels.rename(columns={\n",
        "    \"Complex_word\": \"full_phrase\"\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "0039ce74",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>images</th>\n",
              "      <th>generated_caption</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>image.0.jpg</td>\n",
              "      <td>a black and white bird is standing in the air</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>image.1.jpg</td>\n",
              "      <td>a man with a red hat is standing in front of a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>image.10.jpg</td>\n",
              "      <td>a man is standing in a large white and white a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>image.100.jpg</td>\n",
              "      <td>a man and a woman are playing with a toy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>image.1000.jpg</td>\n",
              "      <td>a person is riding a dirt path in a wooded area</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           images                                  generated_caption\n",
              "0     image.0.jpg      a black and white bird is standing in the air\n",
              "1     image.1.jpg  a man with a red hat is standing in front of a...\n",
              "2    image.10.jpg  a man is standing in a large white and white a...\n",
              "3   image.100.jpg           a man and a woman are playing with a toy\n",
              "4  image.1000.jpg    a person is riding a dirt path in a wooded area"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "caption_data_labels_renamed.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "2b172f5b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>full_phrase</th>\n",
              "      <th>senses</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moorhen swamphen</td>\n",
              "      <td>black gallinule that inhabits ponds and lakes ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>serinus genus</td>\n",
              "      <td>Old World finches; e.g. canaries and serins or...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pegmatite igneous</td>\n",
              "      <td>produced under conditions involving intense he...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bangalore torpedo</td>\n",
              "      <td>an industrial city in south central India (wes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bonxie skua</td>\n",
              "      <td>gull-like jaeger of northern seas or gull-like...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         full_phrase                                             senses\n",
              "0   moorhen swamphen  black gallinule that inhabits ponds and lakes ...\n",
              "1      serinus genus  Old World finches; e.g. canaries and serins or...\n",
              "2  pegmatite igneous  produced under conditions involving intense he...\n",
              "3  bangalore torpedo  an industrial city in south central India (wes...\n",
              "4        bonxie skua  gull-like jaeger of northern seas or gull-like..."
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wordnet_senses_labels_renamed.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "10bca0bf",
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = dataset.merge(wordnet_senses_labels_renamed, how=\"inner\", on=\"full_phrase\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "b6a20125",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target_word</th>\n",
              "      <th>full_phrase</th>\n",
              "      <th>image_0</th>\n",
              "      <th>image_1</th>\n",
              "      <th>image_2</th>\n",
              "      <th>image_3</th>\n",
              "      <th>image_4</th>\n",
              "      <th>image_5</th>\n",
              "      <th>image_6</th>\n",
              "      <th>image_7</th>\n",
              "      <th>image_8</th>\n",
              "      <th>image_9</th>\n",
              "      <th>gold_images</th>\n",
              "      <th>senses</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moorhen</td>\n",
              "      <td>moorhen swamphen</td>\n",
              "      <td>image.3.jpg</td>\n",
              "      <td>image.8.jpg</td>\n",
              "      <td>image.4.jpg</td>\n",
              "      <td>image.1.jpg</td>\n",
              "      <td>image.2.jpg</td>\n",
              "      <td>image.0.jpg</td>\n",
              "      <td>image.5.jpg</td>\n",
              "      <td>image.6.jpg</td>\n",
              "      <td>image.7.jpg</td>\n",
              "      <td>image.9.jpg</td>\n",
              "      <td>image.0.jpg</td>\n",
              "      <td>black gallinule that inhabits ponds and lakes ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>serinus</td>\n",
              "      <td>serinus genus</td>\n",
              "      <td>image.3.jpg</td>\n",
              "      <td>image.23.jpg</td>\n",
              "      <td>image.4.jpg</td>\n",
              "      <td>image.1.jpg</td>\n",
              "      <td>image.2.jpg</td>\n",
              "      <td>image.20.jpg</td>\n",
              "      <td>image.5.jpg</td>\n",
              "      <td>image.24.jpg</td>\n",
              "      <td>image.22.jpg</td>\n",
              "      <td>image.21.jpg</td>\n",
              "      <td>image.20.jpg</td>\n",
              "      <td>Old World finches; e.g. canaries and serins or...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pegmatite</td>\n",
              "      <td>pegmatite igneous</td>\n",
              "      <td>image.41.jpg</td>\n",
              "      <td>image.39.jpg</td>\n",
              "      <td>image.42.jpg</td>\n",
              "      <td>image.43.jpg</td>\n",
              "      <td>image.40.jpg</td>\n",
              "      <td>image.44.jpg</td>\n",
              "      <td>image.37.jpg</td>\n",
              "      <td>image.38.jpg</td>\n",
              "      <td>image.36.jpg</td>\n",
              "      <td>image.35.jpg</td>\n",
              "      <td>image.35.jpg</td>\n",
              "      <td>produced under conditions involving intense he...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bonxie</td>\n",
              "      <td>bonxie skua</td>\n",
              "      <td>image.3.jpg</td>\n",
              "      <td>image.77.jpg</td>\n",
              "      <td>image.78.jpg</td>\n",
              "      <td>image.4.jpg</td>\n",
              "      <td>image.1.jpg</td>\n",
              "      <td>image.2.jpg</td>\n",
              "      <td>image.5.jpg</td>\n",
              "      <td>image.79.jpg</td>\n",
              "      <td>image.76.jpg</td>\n",
              "      <td>image.75.jpg</td>\n",
              "      <td>image.75.jpg</td>\n",
              "      <td>gull-like jaeger of northern seas or gull-like...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ixia</td>\n",
              "      <td>ixia genus</td>\n",
              "      <td>image.90.jpg</td>\n",
              "      <td>image.3.jpg</td>\n",
              "      <td>image.91.jpg</td>\n",
              "      <td>image.4.jpg</td>\n",
              "      <td>image.92.jpg</td>\n",
              "      <td>image.1.jpg</td>\n",
              "      <td>image.2.jpg</td>\n",
              "      <td>image.94.jpg</td>\n",
              "      <td>image.93.jpg</td>\n",
              "      <td>image.5.jpg</td>\n",
              "      <td>image.90.jpg</td>\n",
              "      <td>a monocotyledonous genus of the family Iridace...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  target_word        full_phrase       image_0       image_1       image_2  \\\n",
              "0     moorhen   moorhen swamphen   image.3.jpg   image.8.jpg   image.4.jpg   \n",
              "1     serinus      serinus genus   image.3.jpg  image.23.jpg   image.4.jpg   \n",
              "2   pegmatite  pegmatite igneous  image.41.jpg  image.39.jpg  image.42.jpg   \n",
              "3      bonxie        bonxie skua   image.3.jpg  image.77.jpg  image.78.jpg   \n",
              "4        ixia         ixia genus  image.90.jpg   image.3.jpg  image.91.jpg   \n",
              "\n",
              "        image_3       image_4       image_5       image_6       image_7  \\\n",
              "0   image.1.jpg   image.2.jpg   image.0.jpg   image.5.jpg   image.6.jpg   \n",
              "1   image.1.jpg   image.2.jpg  image.20.jpg   image.5.jpg  image.24.jpg   \n",
              "2  image.43.jpg  image.40.jpg  image.44.jpg  image.37.jpg  image.38.jpg   \n",
              "3   image.4.jpg   image.1.jpg   image.2.jpg   image.5.jpg  image.79.jpg   \n",
              "4   image.4.jpg  image.92.jpg   image.1.jpg   image.2.jpg  image.94.jpg   \n",
              "\n",
              "        image_8       image_9   gold_images  \\\n",
              "0   image.7.jpg   image.9.jpg   image.0.jpg   \n",
              "1  image.22.jpg  image.21.jpg  image.20.jpg   \n",
              "2  image.36.jpg  image.35.jpg  image.35.jpg   \n",
              "3  image.76.jpg  image.75.jpg  image.75.jpg   \n",
              "4  image.93.jpg   image.5.jpg  image.90.jpg   \n",
              "\n",
              "                                              senses  \n",
              "0  black gallinule that inhabits ponds and lakes ...  \n",
              "1  Old World finches; e.g. canaries and serins or...  \n",
              "2  produced under conditions involving intense he...  \n",
              "3  gull-like jaeger of northern seas or gull-like...  \n",
              "4  a monocotyledonous genus of the family Iridace...  "
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "dc38d9ae",
      "metadata": {},
      "source": [
        "Remove any missing data from the generated `senses`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "fa394f50",
      "metadata": {},
      "outputs": [],
      "source": [
        "for missing_data in np.where(dataset.isnull()):\n",
        "    dataset = dataset.drop(missing_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "eb360595",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([], dtype=int64), array([], dtype=int64))"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check if the missing data are dropped (numpy array should appear empty)\n",
        "np.where(dataset.isnull())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "1be928fd",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target_word</th>\n",
              "      <th>full_phrase</th>\n",
              "      <th>image_0</th>\n",
              "      <th>image_1</th>\n",
              "      <th>image_2</th>\n",
              "      <th>image_3</th>\n",
              "      <th>image_4</th>\n",
              "      <th>image_5</th>\n",
              "      <th>image_6</th>\n",
              "      <th>image_7</th>\n",
              "      <th>image_8</th>\n",
              "      <th>image_9</th>\n",
              "      <th>gold_images</th>\n",
              "      <th>senses</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moorhen</td>\n",
              "      <td>moorhen swamphen</td>\n",
              "      <td>image.3.jpg</td>\n",
              "      <td>image.8.jpg</td>\n",
              "      <td>image.4.jpg</td>\n",
              "      <td>image.1.jpg</td>\n",
              "      <td>image.2.jpg</td>\n",
              "      <td>image.0.jpg</td>\n",
              "      <td>image.5.jpg</td>\n",
              "      <td>image.6.jpg</td>\n",
              "      <td>image.7.jpg</td>\n",
              "      <td>image.9.jpg</td>\n",
              "      <td>image.0.jpg</td>\n",
              "      <td>black gallinule that inhabits ponds and lakes ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>serinus</td>\n",
              "      <td>serinus genus</td>\n",
              "      <td>image.3.jpg</td>\n",
              "      <td>image.23.jpg</td>\n",
              "      <td>image.4.jpg</td>\n",
              "      <td>image.1.jpg</td>\n",
              "      <td>image.2.jpg</td>\n",
              "      <td>image.20.jpg</td>\n",
              "      <td>image.5.jpg</td>\n",
              "      <td>image.24.jpg</td>\n",
              "      <td>image.22.jpg</td>\n",
              "      <td>image.21.jpg</td>\n",
              "      <td>image.20.jpg</td>\n",
              "      <td>Old World finches; e.g. canaries and serins or...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pegmatite</td>\n",
              "      <td>pegmatite igneous</td>\n",
              "      <td>image.41.jpg</td>\n",
              "      <td>image.39.jpg</td>\n",
              "      <td>image.42.jpg</td>\n",
              "      <td>image.43.jpg</td>\n",
              "      <td>image.40.jpg</td>\n",
              "      <td>image.44.jpg</td>\n",
              "      <td>image.37.jpg</td>\n",
              "      <td>image.38.jpg</td>\n",
              "      <td>image.36.jpg</td>\n",
              "      <td>image.35.jpg</td>\n",
              "      <td>image.35.jpg</td>\n",
              "      <td>produced under conditions involving intense he...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bonxie</td>\n",
              "      <td>bonxie skua</td>\n",
              "      <td>image.3.jpg</td>\n",
              "      <td>image.77.jpg</td>\n",
              "      <td>image.78.jpg</td>\n",
              "      <td>image.4.jpg</td>\n",
              "      <td>image.1.jpg</td>\n",
              "      <td>image.2.jpg</td>\n",
              "      <td>image.5.jpg</td>\n",
              "      <td>image.79.jpg</td>\n",
              "      <td>image.76.jpg</td>\n",
              "      <td>image.75.jpg</td>\n",
              "      <td>image.75.jpg</td>\n",
              "      <td>gull-like jaeger of northern seas or gull-like...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ixia</td>\n",
              "      <td>ixia genus</td>\n",
              "      <td>image.90.jpg</td>\n",
              "      <td>image.3.jpg</td>\n",
              "      <td>image.91.jpg</td>\n",
              "      <td>image.4.jpg</td>\n",
              "      <td>image.92.jpg</td>\n",
              "      <td>image.1.jpg</td>\n",
              "      <td>image.2.jpg</td>\n",
              "      <td>image.94.jpg</td>\n",
              "      <td>image.93.jpg</td>\n",
              "      <td>image.5.jpg</td>\n",
              "      <td>image.90.jpg</td>\n",
              "      <td>a monocotyledonous genus of the family Iridace...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  target_word        full_phrase       image_0       image_1       image_2  \\\n",
              "0     moorhen   moorhen swamphen   image.3.jpg   image.8.jpg   image.4.jpg   \n",
              "1     serinus      serinus genus   image.3.jpg  image.23.jpg   image.4.jpg   \n",
              "2   pegmatite  pegmatite igneous  image.41.jpg  image.39.jpg  image.42.jpg   \n",
              "3      bonxie        bonxie skua   image.3.jpg  image.77.jpg  image.78.jpg   \n",
              "4        ixia         ixia genus  image.90.jpg   image.3.jpg  image.91.jpg   \n",
              "\n",
              "        image_3       image_4       image_5       image_6       image_7  \\\n",
              "0   image.1.jpg   image.2.jpg   image.0.jpg   image.5.jpg   image.6.jpg   \n",
              "1   image.1.jpg   image.2.jpg  image.20.jpg   image.5.jpg  image.24.jpg   \n",
              "2  image.43.jpg  image.40.jpg  image.44.jpg  image.37.jpg  image.38.jpg   \n",
              "3   image.4.jpg   image.1.jpg   image.2.jpg   image.5.jpg  image.79.jpg   \n",
              "4   image.4.jpg  image.92.jpg   image.1.jpg   image.2.jpg  image.94.jpg   \n",
              "\n",
              "        image_8       image_9   gold_images  \\\n",
              "0   image.7.jpg   image.9.jpg   image.0.jpg   \n",
              "1  image.22.jpg  image.21.jpg  image.20.jpg   \n",
              "2  image.36.jpg  image.35.jpg  image.35.jpg   \n",
              "3  image.76.jpg  image.75.jpg  image.75.jpg   \n",
              "4  image.93.jpg   image.5.jpg  image.90.jpg   \n",
              "\n",
              "                                              senses  \n",
              "0  black gallinule that inhabits ponds and lakes ...  \n",
              "1  Old World finches; e.g. canaries and serins or...  \n",
              "2  produced under conditions involving intense he...  \n",
              "3  gull-like jaeger of northern seas or gull-like...  \n",
              "4  a monocotyledonous genus of the family Iridace...  "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "c2781180",
      "metadata": {},
      "source": [
        "# Word2Vec model\n",
        "\n",
        "Reference (https://www.tensorflow.org/tutorials/text/word2vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "1714557c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import io\n",
        "import re\n",
        "import string\n",
        "import tqdm\n",
        "\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "702ef47b",
      "metadata": {},
      "outputs": [],
      "source": [
        "SEED = 42\n",
        "AUTOTUNE = tf.data.AUTOTUNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "c4857343",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the vocabulary size and the number of words in a sequence.\n",
        "VOCAB_SIZE = 4096\n",
        "SEQUENCE_LENGTH = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "5397de55",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generates skip-gram pairs with negative sampling for a list of sequences\n",
        "# (int-encoded sentences) based on window size, number of negative samples\n",
        "# and vocabulary size.\n",
        "def generate_training_data(sequences, window_size, num_ns, vocab_size, seed):\n",
        "  # Elements of each training example are appended to these lists.\n",
        "  targets, contexts, labels = [], [], []\n",
        "\n",
        "  # Build the sampling table for `vocab_size` tokens.\n",
        "  sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(vocab_size)\n",
        "\n",
        "  # Iterate over all sequences (sentences) in the dataset.\n",
        "  for sequence in tqdm.tqdm(sequences):\n",
        "\n",
        "    # Generate positive skip-gram pairs for a sequence (sentence).\n",
        "    positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
        "          sequence,\n",
        "          vocabulary_size=vocab_size,\n",
        "          sampling_table=sampling_table,\n",
        "          window_size=window_size,\n",
        "          negative_samples=0)\n",
        "\n",
        "    # Iterate over each positive skip-gram pair to produce training examples\n",
        "    # with a positive context word and negative samples.\n",
        "    for target_word, context_word in positive_skip_grams:\n",
        "      context_class = tf.expand_dims(\n",
        "          tf.constant([context_word], dtype=\"int64\"), 1)\n",
        "      negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
        "          true_classes=context_class,\n",
        "          num_true=1,\n",
        "          num_sampled=num_ns,\n",
        "          unique=True,\n",
        "          range_max=vocab_size,\n",
        "          seed=seed,\n",
        "          name=\"negative_sampling\")\n",
        "\n",
        "      # Build context and label vectors (for one target word)\n",
        "      context = tf.concat([tf.squeeze(context_class,1), negative_sampling_candidates], 0)\n",
        "      label = tf.constant([1] + [0]*num_ns, dtype=\"int64\")\n",
        "\n",
        "      # Append each element from the training example to global lists.\n",
        "      targets.append(target_word)\n",
        "      contexts.append(context)\n",
        "      labels.append(label)\n",
        "\n",
        "  return targets, contexts, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "eded2c53",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Now, create a custom standardization function to lowercase the text and\n",
        "# remove punctuation.\n",
        "def custom_standardization(input_data):\n",
        "  lowercase = tf.strings.lower(input_data)\n",
        "  return tf.strings.regex_replace(lowercase,\n",
        "                                  '[%s]' % re.escape(string.punctuation), '')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "b824dd15",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-03-17 00:01:43.480117: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-03-17 00:01:43.526631: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-03-17 00:01:43.526797: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-03-17 00:01:43.527306: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-03-17 00:01:43.527953: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-03-17 00:01:43.528088: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-03-17 00:01:43.528205: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-03-17 00:01:43.890417: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-03-17 00:01:43.890570: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-03-17 00:01:43.890683: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:981] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
            "2023-03-17 00:01:43.890774: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5836 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:07:00.0, compute capability: 8.6\n"
          ]
        }
      ],
      "source": [
        "# Use the `TextVectorization` layer to normalize, split, and map strings to\n",
        "# integers. Set the `output_sequence_length` length to pad all samples to the\n",
        "# same length.\n",
        "vectorize_layer = layers.TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=SEQUENCE_LENGTH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "37552ea9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11722"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dataset) # Size of the dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "184fd065",
      "metadata": {},
      "source": [
        "Reads the `full_phrase` and `senses` then combine them into `result_sense.txt`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "2d30c527",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[result_senses.txt has already been created]\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "# +------------------------------------------------------------+\n",
        "# | had to do this hacky way to make jupyter run the for-loop  |\n",
        "# | probably without repeating the first index of the `dataset`|\n",
        "# +------------------------------------------------------------+\n",
        "list_index = []\n",
        "for index in range(len(dataset)):\n",
        "    if index % 1 == 0:\n",
        "        list_index.append(index)\n",
        "\n",
        "# adds the final index that is not divisible by the mod number\n",
        "if len(dataset) not in list_index:\n",
        "    list_index.append(len(dataset)) \n",
        "\n",
        "\n",
        "if os.path.isfile(path + \"result_senses.txt\") == False:\n",
        "    # i being the first index, y being the index after it\n",
        "    print(\"Creating the senses text files...\")\n",
        "    for i, y in zip(tqdm.tqdm(list_index), list_index[1:]):\n",
        "        file = open(path + \"senses%d.txt\"%y, \"w\")\n",
        "        dataset_senses = \"\"\n",
        "        for full_phrase, senses in zip(dataset.full_phrase[i:y], dataset.senses[i:y]):\n",
        "            dataset_senses +=  full_phrase + \" \" + senses + \" \"\n",
        "            file.write(dataset_senses)\n",
        "        file.close()\n",
        "        del full_phrase, senses  # clears the memory to avoid memory leak\n",
        "    \n",
        "    # Reference (https://stackoverflow.com/a/17749339)\n",
        "    print(\"Combining senses text files into one...\")\n",
        "    senses_files = sorted(glob.glob(path + \"senses*.txt\"))\n",
        "    with open(path + \"result_senses.txt\", \"wb\") as outfile:\n",
        "        for f in tqdm.tqdm(senses_files):\n",
        "            with open(f, \"rb\") as infile:\n",
        "                outfile.write(infile.read())\n",
        "            os.remove(f)\n",
        "        \n",
        "else:\n",
        "    print(\"[result_senses.txt has already been created]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "400670a0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /home/srking501/anaconda3/lib/python3.9/site-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\n",
            "Instructions for updating:\n",
            "Lambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\n"
          ]
        }
      ],
      "source": [
        "text_ds = tf.data.TextLineDataset(path + \"result_senses.txt\").filter(lambda x: tf.cast(tf.strings.length(x), bool))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "902124a9",
      "metadata": {},
      "source": [
        "Vectorize sentences from the corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "f0fd2d81",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Now, create a custom standardization function to lowercase the text and\n",
        "# remove punctuation.\n",
        "def custom_standardization(input_data):\n",
        "  lowercase = tf.strings.lower(input_data)\n",
        "  return tf.strings.regex_replace(lowercase,\n",
        "                                  '[%s]' % re.escape(string.punctuation), '')\n",
        "\n",
        "# Use the `TextVectorization` layer to normalize, split, and map strings to\n",
        "# integers. Set the `output_sequence_length` length to pad all samples to the\n",
        "# same length.\n",
        "vectorize_layer = layers.TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=SEQUENCE_LENGTH)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "bf333971",
      "metadata": {},
      "source": [
        "Call `TextVectorization.adapt` on the text dataset to create vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "id": "4803bf7b",
      "metadata": {},
      "outputs": [],
      "source": [
        "vectorize_layer.adapt(text_ds.batch(1024))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "ca936130",
      "metadata": {},
      "source": [
        "Once the state of the layer has been adapted to represent the text corpus, the vocabulary can be accessed with `TextVectorization.get_vocabulary`. This function returns a list of all vocabulary tokens sorted (descending) by their frequency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "id": "6dc21115",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['', '[UNK]', 'or', 'a', 'of', 'the', 'and', 'in', 'to', 'an', 'that', 'for', 'by', 'with', 'something', 'as', 'one', 'is', 'group', 'genus']\n"
          ]
        }
      ],
      "source": [
        "# Save the created vocabulary for reference.\n",
        "inverse_vocab = vectorize_layer.get_vocabulary()\n",
        "print(inverse_vocab[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42447642",
      "metadata": {},
      "source": [
        "The `vectorize_layer` can now be used to generate vectors for each element in the `text_ds` (a `tf.data.Dataset`). Apply `Dataset.batch`, `Dataset.prefetch`, `Dataset.map`, and `Dataset.unbatch`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "id": "7404fb0a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vectorize the data in text_ds.\n",
        "text_vector_ds = text_ds.batch(1024).prefetch(AUTOTUNE).map(vectorize_layer).unbatch()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "b2cc5602",
      "metadata": {},
      "source": [
        "Obtain sequences from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "id": "de1d88ad",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "sequences = list(text_vector_ds.as_numpy_iterator())\n",
        "print(len(sequences))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "daa703d4",
      "metadata": {},
      "source": [
        "Inspect a few examples from `sequences`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "id": "f691e043",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[   1    1  332    1   10    1    1    6 3609    2] => ['[UNK]', '[UNK]', 'black', '[UNK]', 'that', '[UNK]', '[UNK]', 'and', 'lakes', 'or']\n"
          ]
        }
      ],
      "source": [
        "for seq in sequences[:5]:\n",
        "  print(f\"{seq} => {[inverse_vocab[i] for i in seq]}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "bbe4e753",
      "metadata": {},
      "source": [
        "Generate training examples from sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "2d151b2c",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:00<00:00, 9137.92it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "targets.shape: (0,)\n",
            "contexts.shape: (0,)\n",
            "labels.shape: (0,)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "targets, contexts, labels = generate_training_data(\n",
        "    sequences=sequences,\n",
        "    window_size=2,\n",
        "    num_ns=4,\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    seed=SEED)\n",
        "\n",
        "targets = np.array(targets)\n",
        "contexts = np.array(contexts)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print('\\n')\n",
        "print(f\"targets.shape: {targets.shape}\")\n",
        "print(f\"contexts.shape: {contexts.shape}\")\n",
        "print(f\"labels.shape: {labels.shape}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "cec6ba27",
      "metadata": {},
      "source": [
        "## Training of Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "bb1a33e5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<BatchDataset element_spec=((TensorSpec(shape=(1024,), dtype=tf.float64, name=None), TensorSpec(shape=(1024,), dtype=tf.float64, name=None)), TensorSpec(shape=(1024,), dtype=tf.float64, name=None))>\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 1024\n",
        "BUFFER_SIZE = 10000\n",
        "final_dataset = tf.data.Dataset.from_tensor_slices(((targets, contexts), labels))\n",
        "final_dataset = final_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "print(final_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "2cda96d8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<PrefetchDataset element_spec=((TensorSpec(shape=(1024,), dtype=tf.float64, name=None), TensorSpec(shape=(1024,), dtype=tf.float64, name=None)), TensorSpec(shape=(1024,), dtype=tf.float64, name=None))>\n"
          ]
        }
      ],
      "source": [
        "final_dataset = final_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "print(final_dataset)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "1039c5c0",
      "metadata": {},
      "source": [
        "Subclassed word2vec model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "94d8d663",
      "metadata": {},
      "outputs": [],
      "source": [
        "class Word2Vec(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim):\n",
        "    super(Word2Vec, self).__init__()\n",
        "    self.target_embedding = layers.Embedding(vocab_size,\n",
        "                                      embedding_dim,\n",
        "                                      input_length=1,\n",
        "                                      name=\"w2v_embedding\")\n",
        "    self.context_embedding = layers.Embedding(vocab_size,\n",
        "                                       embedding_dim,\n",
        "                                       input_length=num_ns+1)\n",
        "\n",
        "  def call(self, pair):\n",
        "    target, context = pair\n",
        "    # target: (batch, dummy?)  # The dummy axis doesn't exist in TF2.7+\n",
        "    # context: (batch, context)\n",
        "    if len(target.shape) == 2:\n",
        "      target = tf.squeeze(target, axis=1)\n",
        "    # target: (batch,)\n",
        "    word_emb = self.target_embedding(target)\n",
        "    # word_emb: (batch, embed)\n",
        "    context_emb = self.context_embedding(context)\n",
        "    # context_emb: (batch, context, embed)\n",
        "    dots = tf.einsum('be,bce->bc', word_emb, context_emb)\n",
        "    # dots: (batch, context)\n",
        "    return dots"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "13e4c7eb",
      "metadata": {},
      "source": [
        "Define loss function and compile model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "d96f6dff",
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'num_ns' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipykernel_62902/3304595236.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0membedding_dim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m128\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mword2vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVOCAB_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m word2vec.compile(optimizer='adam',\n\u001b[1;32m      4\u001b[0m                  \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCategoricalCrossentropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfrom_logits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                  metrics=['accuracy'])\n",
            "\u001b[0;32m/tmp/ipykernel_62902/692650658.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, vocab_size, embedding_dim)\u001b[0m\n\u001b[1;32m      8\u001b[0m     self.context_embedding = layers.Embedding(vocab_size,\n\u001b[1;32m      9\u001b[0m                                        \u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                                        input_length=num_ns+1)\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpair\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'num_ns' is not defined"
          ]
        }
      ],
      "source": [
        "embedding_dim = 128\n",
        "word2vec = Word2Vec(VOCAB_SIZE, embedding_dim)\n",
        "word2vec.compile(optimizer='adam',\n",
        "                 loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "                 metrics=['accuracy'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "dad450a28c894495c754ffb1489f7750013982b9a26900c90ef19258e6c32c78"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
