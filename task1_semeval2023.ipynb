{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "7628432b",
      "metadata": {},
      "source": [
        "# [SemEval 2023 Task 1](https://raganato.github.io/vwsd/)\n",
        "\n",
        "[By Abdullah Alshadadi (Srking501)](https://github.com/Srking501)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import keras\n",
        "import random\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "189967aa",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "c9945c50",
      "metadata": {},
      "outputs": [],
      "source": [
        "# to access google drive folder\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive') # When you run this you'll be prompted for a token - follow the link to generate this.\n",
        "# #        \"/content/drive/MyDrive/...path/to/dir\n",
        "# path = \"/content/drive/MyDrive/semeval-2023/task-1/\"\n",
        "# path = \"/content/drive/MyDrive/data/\"\n",
        "\n",
        "# Comment this out if you are using Google Colab, otherwise just change to local directory where the data is located\n",
        "path = \"./data/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "6cbda6ac",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/srking501/Desktop/Projects/Data Science Hackathon/semeval-2023-task1'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.getcwd()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "41358c9d",
      "metadata": {},
      "source": [
        "❗❗❗Retrieve the data from [SemEval-2023 Task-1 page](https://raganato.github.io/vwsd/), specifically the [\"[TRAIN+TRIAL]\" data](https://drive.google.com/file/d/1byX4wpe1UjyCVyYrT04sW17NnycKAK7N/view), and put it into `data/` directory❗❗❗"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "a69f9e46",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Data already unzipped]\n"
          ]
        }
      ],
      "source": [
        "from zipfile import ZipFile\n",
        "\n",
        "try:\n",
        "    if os.path.isdir(path + \"semeval-2023-task-1-V-WSD-train-v1\") == False:\n",
        "        with ZipFile(path + \"semeval-2023-task-1-V-WSD-train-v1.zip\", \"r\") as zip:\n",
        "            print(\"Unzipping data...\")\n",
        "            zip.extractall(\"data/\")\n",
        "            print(\"Finished.\")\n",
        "    else:\n",
        "        print(\"[Data already unzipped]\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"The file semeval-2023-task-1-V-WSD-train-v1.zip is not found in path:\\n\"\n",
        "          f\"{path}\\n\")\n",
        "    print(f\"The contents of {path}:\\n\"\n",
        "          f\"{os.listdir(path)}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "b426d440",
      "metadata": {},
      "source": [
        "To check if we are in the right directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "8c001267",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['.DS_Store',\n",
              " 'captions_train_clean_complete.csv',\n",
              " 'README.md',\n",
              " 'semeval-2023-task-1-V-WSD-train-v1',\n",
              " 'wordnet(individual tokens).csv']"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "os.listdir(path)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "c71d11be",
      "metadata": {},
      "source": [
        "Using `train_v1/` data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "dbd6ef20",
      "metadata": {},
      "outputs": [],
      "source": [
        "path_to_data = path + \"semeval-2023-task-1-V-WSD-train-v1/\"\n",
        "data_labels = pd.read_csv(path_to_data + \"train_v1/train.data.v1.txt\", \n",
        "                sep = \"\\t\", \n",
        "                names = [\"target_word\", \"full_phrase\"] + \n",
        "                [\"image_%d\"%index for index in range(10)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8413dcb7",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target_word</th>\n",
              "      <th>full_phrase</th>\n",
              "      <th>image_0</th>\n",
              "      <th>image_1</th>\n",
              "      <th>image_2</th>\n",
              "      <th>image_3</th>\n",
              "      <th>image_4</th>\n",
              "      <th>image_5</th>\n",
              "      <th>image_6</th>\n",
              "      <th>image_7</th>\n",
              "      <th>image_8</th>\n",
              "      <th>image_9</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moorhen</td>\n",
              "      <td>moorhen swamphen</td>\n",
              "      <td>image.3.jpg</td>\n",
              "      <td>image.8.jpg</td>\n",
              "      <td>image.4.jpg</td>\n",
              "      <td>image.1.jpg</td>\n",
              "      <td>image.2.jpg</td>\n",
              "      <td>image.0.jpg</td>\n",
              "      <td>image.5.jpg</td>\n",
              "      <td>image.6.jpg</td>\n",
              "      <td>image.7.jpg</td>\n",
              "      <td>image.9.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>serinus</td>\n",
              "      <td>serinus genus</td>\n",
              "      <td>image.3.jpg</td>\n",
              "      <td>image.23.jpg</td>\n",
              "      <td>image.4.jpg</td>\n",
              "      <td>image.1.jpg</td>\n",
              "      <td>image.2.jpg</td>\n",
              "      <td>image.20.jpg</td>\n",
              "      <td>image.5.jpg</td>\n",
              "      <td>image.24.jpg</td>\n",
              "      <td>image.22.jpg</td>\n",
              "      <td>image.21.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pegmatite</td>\n",
              "      <td>pegmatite igneous</td>\n",
              "      <td>image.41.jpg</td>\n",
              "      <td>image.39.jpg</td>\n",
              "      <td>image.42.jpg</td>\n",
              "      <td>image.43.jpg</td>\n",
              "      <td>image.40.jpg</td>\n",
              "      <td>image.44.jpg</td>\n",
              "      <td>image.37.jpg</td>\n",
              "      <td>image.38.jpg</td>\n",
              "      <td>image.36.jpg</td>\n",
              "      <td>image.35.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bangalores</td>\n",
              "      <td>bangalores torpedo</td>\n",
              "      <td>image.58.jpg</td>\n",
              "      <td>image.59.jpg</td>\n",
              "      <td>image.64.jpg</td>\n",
              "      <td>image.57.jpg</td>\n",
              "      <td>image.55.jpg</td>\n",
              "      <td>image.56.jpg</td>\n",
              "      <td>image.62.jpg</td>\n",
              "      <td>image.63.jpg</td>\n",
              "      <td>image.61.jpg</td>\n",
              "      <td>image.60.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bonxie</td>\n",
              "      <td>bonxie skua</td>\n",
              "      <td>image.3.jpg</td>\n",
              "      <td>image.77.jpg</td>\n",
              "      <td>image.78.jpg</td>\n",
              "      <td>image.4.jpg</td>\n",
              "      <td>image.1.jpg</td>\n",
              "      <td>image.2.jpg</td>\n",
              "      <td>image.5.jpg</td>\n",
              "      <td>image.79.jpg</td>\n",
              "      <td>image.76.jpg</td>\n",
              "      <td>image.75.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  target_word         full_phrase       image_0       image_1       image_2  \\\n",
              "0     moorhen    moorhen swamphen   image.3.jpg   image.8.jpg   image.4.jpg   \n",
              "1     serinus       serinus genus   image.3.jpg  image.23.jpg   image.4.jpg   \n",
              "2   pegmatite   pegmatite igneous  image.41.jpg  image.39.jpg  image.42.jpg   \n",
              "3  bangalores  bangalores torpedo  image.58.jpg  image.59.jpg  image.64.jpg   \n",
              "4      bonxie         bonxie skua   image.3.jpg  image.77.jpg  image.78.jpg   \n",
              "\n",
              "        image_3       image_4       image_5       image_6       image_7  \\\n",
              "0   image.1.jpg   image.2.jpg   image.0.jpg   image.5.jpg   image.6.jpg   \n",
              "1   image.1.jpg   image.2.jpg  image.20.jpg   image.5.jpg  image.24.jpg   \n",
              "2  image.43.jpg  image.40.jpg  image.44.jpg  image.37.jpg  image.38.jpg   \n",
              "3  image.57.jpg  image.55.jpg  image.56.jpg  image.62.jpg  image.63.jpg   \n",
              "4   image.4.jpg   image.1.jpg   image.2.jpg   image.5.jpg  image.79.jpg   \n",
              "\n",
              "        image_8       image_9  \n",
              "0   image.7.jpg   image.9.jpg  \n",
              "1  image.22.jpg  image.21.jpg  \n",
              "2  image.36.jpg  image.35.jpg  \n",
              "3  image.61.jpg  image.60.jpg  \n",
              "4  image.76.jpg  image.75.jpg  "
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data_labels.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6a08dbce",
      "metadata": {},
      "outputs": [],
      "source": [
        "gold_labels = pd.read_csv(path_to_data + \"train_v1/train.gold.v1.txt\", \n",
        "                    names = [\"gold_images\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "c468a123",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>gold_images</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>image.0.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>image.20.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>image.35.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>image.55.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>image.75.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    gold_images\n",
              "0   image.0.jpg\n",
              "1  image.20.jpg\n",
              "2  image.35.jpg\n",
              "3  image.55.jpg\n",
              "4  image.75.jpg"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "gold_labels.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "19764c2c",
      "metadata": {},
      "source": [
        "Image Caption Data and WordNet senses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "1931fd43",
      "metadata": {},
      "outputs": [],
      "source": [
        "caption_data_labels = pd.read_csv(path + \"captions_train_clean_complete.csv\")\n",
        "wordnet_senses_labels = pd.read_csv(path + \"wordnet(individual tokens).csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "1abd655d",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>File Name</th>\n",
              "      <th>Generated Caption</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>image.0.jpg</td>\n",
              "      <td>a black and white bird is standing in the air</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>image.1.jpg</td>\n",
              "      <td>a man with a red hat is standing in front of a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>image.10.jpg</td>\n",
              "      <td>a man is standing in a large white and white a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>image.100.jpg</td>\n",
              "      <td>a man and a woman are playing with a toy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>image.1000.jpg</td>\n",
              "      <td>a person is riding a dirt path in a wooded area</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        File Name                                  Generated Caption\n",
              "0     image.0.jpg      a black and white bird is standing in the air\n",
              "1     image.1.jpg  a man with a red hat is standing in front of a...\n",
              "2    image.10.jpg  a man is standing in a large white and white a...\n",
              "3   image.100.jpg           a man and a woman are playing with a toy\n",
              "4  image.1000.jpg    a person is riding a dirt path in a wooded area"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "caption_data_labels.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "b751834b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Complex_word</th>\n",
              "      <th>senses</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moorhen swamphen</td>\n",
              "      <td>black gallinule that inhabits ponds and lakes ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>serinus genus</td>\n",
              "      <td>Old World finches; e.g. canaries and serins or...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pegmatite igneous</td>\n",
              "      <td>produced under conditions involving intense he...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bangalore torpedo</td>\n",
              "      <td>an industrial city in south central India (wes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bonxie skua</td>\n",
              "      <td>gull-like jaeger of northern seas or gull-like...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Complex_word                                             senses\n",
              "0   moorhen swamphen  black gallinule that inhabits ponds and lakes ...\n",
              "1      serinus genus  Old World finches; e.g. canaries and serins or...\n",
              "2  pegmatite igneous  produced under conditions involving intense he...\n",
              "3  bangalore torpedo  an industrial city in south central India (wes...\n",
              "4        bonxie skua  gull-like jaeger of northern seas or gull-like..."
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wordnet_senses_labels.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "7fa11a7b",
      "metadata": {},
      "source": [
        "## Creating the main `dataset`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "22887baf",
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = data_labels.join(gold_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "d7834333",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target_word</th>\n",
              "      <th>full_phrase</th>\n",
              "      <th>image_0</th>\n",
              "      <th>image_1</th>\n",
              "      <th>image_2</th>\n",
              "      <th>image_3</th>\n",
              "      <th>image_4</th>\n",
              "      <th>image_5</th>\n",
              "      <th>image_6</th>\n",
              "      <th>image_7</th>\n",
              "      <th>image_8</th>\n",
              "      <th>image_9</th>\n",
              "      <th>gold_images</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moorhen</td>\n",
              "      <td>moorhen swamphen</td>\n",
              "      <td>image.3.jpg</td>\n",
              "      <td>image.8.jpg</td>\n",
              "      <td>image.4.jpg</td>\n",
              "      <td>image.1.jpg</td>\n",
              "      <td>image.2.jpg</td>\n",
              "      <td>image.0.jpg</td>\n",
              "      <td>image.5.jpg</td>\n",
              "      <td>image.6.jpg</td>\n",
              "      <td>image.7.jpg</td>\n",
              "      <td>image.9.jpg</td>\n",
              "      <td>image.0.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>serinus</td>\n",
              "      <td>serinus genus</td>\n",
              "      <td>image.3.jpg</td>\n",
              "      <td>image.23.jpg</td>\n",
              "      <td>image.4.jpg</td>\n",
              "      <td>image.1.jpg</td>\n",
              "      <td>image.2.jpg</td>\n",
              "      <td>image.20.jpg</td>\n",
              "      <td>image.5.jpg</td>\n",
              "      <td>image.24.jpg</td>\n",
              "      <td>image.22.jpg</td>\n",
              "      <td>image.21.jpg</td>\n",
              "      <td>image.20.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pegmatite</td>\n",
              "      <td>pegmatite igneous</td>\n",
              "      <td>image.41.jpg</td>\n",
              "      <td>image.39.jpg</td>\n",
              "      <td>image.42.jpg</td>\n",
              "      <td>image.43.jpg</td>\n",
              "      <td>image.40.jpg</td>\n",
              "      <td>image.44.jpg</td>\n",
              "      <td>image.37.jpg</td>\n",
              "      <td>image.38.jpg</td>\n",
              "      <td>image.36.jpg</td>\n",
              "      <td>image.35.jpg</td>\n",
              "      <td>image.35.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bangalores</td>\n",
              "      <td>bangalores torpedo</td>\n",
              "      <td>image.58.jpg</td>\n",
              "      <td>image.59.jpg</td>\n",
              "      <td>image.64.jpg</td>\n",
              "      <td>image.57.jpg</td>\n",
              "      <td>image.55.jpg</td>\n",
              "      <td>image.56.jpg</td>\n",
              "      <td>image.62.jpg</td>\n",
              "      <td>image.63.jpg</td>\n",
              "      <td>image.61.jpg</td>\n",
              "      <td>image.60.jpg</td>\n",
              "      <td>image.55.jpg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bonxie</td>\n",
              "      <td>bonxie skua</td>\n",
              "      <td>image.3.jpg</td>\n",
              "      <td>image.77.jpg</td>\n",
              "      <td>image.78.jpg</td>\n",
              "      <td>image.4.jpg</td>\n",
              "      <td>image.1.jpg</td>\n",
              "      <td>image.2.jpg</td>\n",
              "      <td>image.5.jpg</td>\n",
              "      <td>image.79.jpg</td>\n",
              "      <td>image.76.jpg</td>\n",
              "      <td>image.75.jpg</td>\n",
              "      <td>image.75.jpg</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  target_word         full_phrase       image_0       image_1       image_2  \\\n",
              "0     moorhen    moorhen swamphen   image.3.jpg   image.8.jpg   image.4.jpg   \n",
              "1     serinus       serinus genus   image.3.jpg  image.23.jpg   image.4.jpg   \n",
              "2   pegmatite   pegmatite igneous  image.41.jpg  image.39.jpg  image.42.jpg   \n",
              "3  bangalores  bangalores torpedo  image.58.jpg  image.59.jpg  image.64.jpg   \n",
              "4      bonxie         bonxie skua   image.3.jpg  image.77.jpg  image.78.jpg   \n",
              "\n",
              "        image_3       image_4       image_5       image_6       image_7  \\\n",
              "0   image.1.jpg   image.2.jpg   image.0.jpg   image.5.jpg   image.6.jpg   \n",
              "1   image.1.jpg   image.2.jpg  image.20.jpg   image.5.jpg  image.24.jpg   \n",
              "2  image.43.jpg  image.40.jpg  image.44.jpg  image.37.jpg  image.38.jpg   \n",
              "3  image.57.jpg  image.55.jpg  image.56.jpg  image.62.jpg  image.63.jpg   \n",
              "4   image.4.jpg   image.1.jpg   image.2.jpg   image.5.jpg  image.79.jpg   \n",
              "\n",
              "        image_8       image_9   gold_images  \n",
              "0   image.7.jpg   image.9.jpg   image.0.jpg  \n",
              "1  image.22.jpg  image.21.jpg  image.20.jpg  \n",
              "2  image.36.jpg  image.35.jpg  image.35.jpg  \n",
              "3  image.61.jpg  image.60.jpg  image.55.jpg  \n",
              "4  image.76.jpg  image.75.jpg  image.75.jpg  "
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "3dd2f653",
      "metadata": {},
      "source": [
        "The only important dataframes are `caption_data_labels_renamed` and the newly merged `wordnet_senses_labels_renamed` into the main `dataset` dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "a0e28b6a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# renaming columns to match the `data_labels` dataframe and \n",
        "# to fit one standard format \n",
        "# (following the python naming convention - \n",
        "# https://peps.python.org/pep-0008/#naming-conventions)\n",
        "#\n",
        "caption_data_labels_renamed = caption_data_labels.rename(columns={\n",
        "    \"File Name\": \"images\",\n",
        "    \"Generated Caption\": \"generated_caption\"\n",
        "    })\n",
        "wordnet_senses_labels_renamed = wordnet_senses_labels.rename(columns={\n",
        "    \"Complex_word\": \"full_phrase\"\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "0039ce74",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>images</th>\n",
              "      <th>generated_caption</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>image.0.jpg</td>\n",
              "      <td>a black and white bird is standing in the air</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>image.1.jpg</td>\n",
              "      <td>a man with a red hat is standing in front of a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>image.10.jpg</td>\n",
              "      <td>a man is standing in a large white and white a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>image.100.jpg</td>\n",
              "      <td>a man and a woman are playing with a toy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>image.1000.jpg</td>\n",
              "      <td>a person is riding a dirt path in a wooded area</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           images                                  generated_caption\n",
              "0     image.0.jpg      a black and white bird is standing in the air\n",
              "1     image.1.jpg  a man with a red hat is standing in front of a...\n",
              "2    image.10.jpg  a man is standing in a large white and white a...\n",
              "3   image.100.jpg           a man and a woman are playing with a toy\n",
              "4  image.1000.jpg    a person is riding a dirt path in a wooded area"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "caption_data_labels_renamed.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "2b172f5b",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>full_phrase</th>\n",
              "      <th>senses</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moorhen swamphen</td>\n",
              "      <td>black gallinule that inhabits ponds and lakes ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>serinus genus</td>\n",
              "      <td>Old World finches; e.g. canaries and serins or...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pegmatite igneous</td>\n",
              "      <td>produced under conditions involving intense he...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bangalore torpedo</td>\n",
              "      <td>an industrial city in south central India (wes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>bonxie skua</td>\n",
              "      <td>gull-like jaeger of northern seas or gull-like...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         full_phrase                                             senses\n",
              "0   moorhen swamphen  black gallinule that inhabits ponds and lakes ...\n",
              "1      serinus genus  Old World finches; e.g. canaries and serins or...\n",
              "2  pegmatite igneous  produced under conditions involving intense he...\n",
              "3  bangalore torpedo  an industrial city in south central India (wes...\n",
              "4        bonxie skua  gull-like jaeger of northern seas or gull-like..."
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "wordnet_senses_labels_renamed.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "10bca0bf",
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = dataset.merge(wordnet_senses_labels_renamed, how=\"inner\", on=\"full_phrase\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "b6a20125",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target_word</th>\n",
              "      <th>full_phrase</th>\n",
              "      <th>image_0</th>\n",
              "      <th>image_1</th>\n",
              "      <th>image_2</th>\n",
              "      <th>image_3</th>\n",
              "      <th>image_4</th>\n",
              "      <th>image_5</th>\n",
              "      <th>image_6</th>\n",
              "      <th>image_7</th>\n",
              "      <th>image_8</th>\n",
              "      <th>image_9</th>\n",
              "      <th>gold_images</th>\n",
              "      <th>senses</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moorhen</td>\n",
              "      <td>moorhen swamphen</td>\n",
              "      <td>image.3.jpg</td>\n",
              "      <td>image.8.jpg</td>\n",
              "      <td>image.4.jpg</td>\n",
              "      <td>image.1.jpg</td>\n",
              "      <td>image.2.jpg</td>\n",
              "      <td>image.0.jpg</td>\n",
              "      <td>image.5.jpg</td>\n",
              "      <td>image.6.jpg</td>\n",
              "      <td>image.7.jpg</td>\n",
              "      <td>image.9.jpg</td>\n",
              "      <td>image.0.jpg</td>\n",
              "      <td>black gallinule that inhabits ponds and lakes ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>serinus</td>\n",
              "      <td>serinus genus</td>\n",
              "      <td>image.3.jpg</td>\n",
              "      <td>image.23.jpg</td>\n",
              "      <td>image.4.jpg</td>\n",
              "      <td>image.1.jpg</td>\n",
              "      <td>image.2.jpg</td>\n",
              "      <td>image.20.jpg</td>\n",
              "      <td>image.5.jpg</td>\n",
              "      <td>image.24.jpg</td>\n",
              "      <td>image.22.jpg</td>\n",
              "      <td>image.21.jpg</td>\n",
              "      <td>image.20.jpg</td>\n",
              "      <td>Old World finches; e.g. canaries and serins or...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pegmatite</td>\n",
              "      <td>pegmatite igneous</td>\n",
              "      <td>image.41.jpg</td>\n",
              "      <td>image.39.jpg</td>\n",
              "      <td>image.42.jpg</td>\n",
              "      <td>image.43.jpg</td>\n",
              "      <td>image.40.jpg</td>\n",
              "      <td>image.44.jpg</td>\n",
              "      <td>image.37.jpg</td>\n",
              "      <td>image.38.jpg</td>\n",
              "      <td>image.36.jpg</td>\n",
              "      <td>image.35.jpg</td>\n",
              "      <td>image.35.jpg</td>\n",
              "      <td>produced under conditions involving intense he...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bonxie</td>\n",
              "      <td>bonxie skua</td>\n",
              "      <td>image.3.jpg</td>\n",
              "      <td>image.77.jpg</td>\n",
              "      <td>image.78.jpg</td>\n",
              "      <td>image.4.jpg</td>\n",
              "      <td>image.1.jpg</td>\n",
              "      <td>image.2.jpg</td>\n",
              "      <td>image.5.jpg</td>\n",
              "      <td>image.79.jpg</td>\n",
              "      <td>image.76.jpg</td>\n",
              "      <td>image.75.jpg</td>\n",
              "      <td>image.75.jpg</td>\n",
              "      <td>gull-like jaeger of northern seas or gull-like...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ixia</td>\n",
              "      <td>ixia genus</td>\n",
              "      <td>image.90.jpg</td>\n",
              "      <td>image.3.jpg</td>\n",
              "      <td>image.91.jpg</td>\n",
              "      <td>image.4.jpg</td>\n",
              "      <td>image.92.jpg</td>\n",
              "      <td>image.1.jpg</td>\n",
              "      <td>image.2.jpg</td>\n",
              "      <td>image.94.jpg</td>\n",
              "      <td>image.93.jpg</td>\n",
              "      <td>image.5.jpg</td>\n",
              "      <td>image.90.jpg</td>\n",
              "      <td>a monocotyledonous genus of the family Iridace...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  target_word        full_phrase       image_0       image_1       image_2  \\\n",
              "0     moorhen   moorhen swamphen   image.3.jpg   image.8.jpg   image.4.jpg   \n",
              "1     serinus      serinus genus   image.3.jpg  image.23.jpg   image.4.jpg   \n",
              "2   pegmatite  pegmatite igneous  image.41.jpg  image.39.jpg  image.42.jpg   \n",
              "3      bonxie        bonxie skua   image.3.jpg  image.77.jpg  image.78.jpg   \n",
              "4        ixia         ixia genus  image.90.jpg   image.3.jpg  image.91.jpg   \n",
              "\n",
              "        image_3       image_4       image_5       image_6       image_7  \\\n",
              "0   image.1.jpg   image.2.jpg   image.0.jpg   image.5.jpg   image.6.jpg   \n",
              "1   image.1.jpg   image.2.jpg  image.20.jpg   image.5.jpg  image.24.jpg   \n",
              "2  image.43.jpg  image.40.jpg  image.44.jpg  image.37.jpg  image.38.jpg   \n",
              "3   image.4.jpg   image.1.jpg   image.2.jpg   image.5.jpg  image.79.jpg   \n",
              "4   image.4.jpg  image.92.jpg   image.1.jpg   image.2.jpg  image.94.jpg   \n",
              "\n",
              "        image_8       image_9   gold_images  \\\n",
              "0   image.7.jpg   image.9.jpg   image.0.jpg   \n",
              "1  image.22.jpg  image.21.jpg  image.20.jpg   \n",
              "2  image.36.jpg  image.35.jpg  image.35.jpg   \n",
              "3  image.76.jpg  image.75.jpg  image.75.jpg   \n",
              "4  image.93.jpg   image.5.jpg  image.90.jpg   \n",
              "\n",
              "                                              senses  \n",
              "0  black gallinule that inhabits ponds and lakes ...  \n",
              "1  Old World finches; e.g. canaries and serins or...  \n",
              "2  produced under conditions involving intense he...  \n",
              "3  gull-like jaeger of northern seas or gull-like...  \n",
              "4  a monocotyledonous genus of the family Iridace...  "
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "dc38d9ae",
      "metadata": {},
      "source": [
        "Remove any missing data from the generated `senses`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "fa394f50",
      "metadata": {},
      "outputs": [],
      "source": [
        "for missing_data in np.where(dataset.isnull()):\n",
        "    dataset = dataset.drop(missing_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "eb360595",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([], dtype=int64), array([], dtype=int64))"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Check if the missing data are dropped (numpy array should appear empty)\n",
        "np.where(dataset.isnull())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "1be928fd",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>target_word</th>\n",
              "      <th>full_phrase</th>\n",
              "      <th>image_0</th>\n",
              "      <th>image_1</th>\n",
              "      <th>image_2</th>\n",
              "      <th>image_3</th>\n",
              "      <th>image_4</th>\n",
              "      <th>image_5</th>\n",
              "      <th>image_6</th>\n",
              "      <th>image_7</th>\n",
              "      <th>image_8</th>\n",
              "      <th>image_9</th>\n",
              "      <th>gold_images</th>\n",
              "      <th>senses</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>moorhen</td>\n",
              "      <td>moorhen swamphen</td>\n",
              "      <td>image.3.jpg</td>\n",
              "      <td>image.8.jpg</td>\n",
              "      <td>image.4.jpg</td>\n",
              "      <td>image.1.jpg</td>\n",
              "      <td>image.2.jpg</td>\n",
              "      <td>image.0.jpg</td>\n",
              "      <td>image.5.jpg</td>\n",
              "      <td>image.6.jpg</td>\n",
              "      <td>image.7.jpg</td>\n",
              "      <td>image.9.jpg</td>\n",
              "      <td>image.0.jpg</td>\n",
              "      <td>black gallinule that inhabits ponds and lakes ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>serinus</td>\n",
              "      <td>serinus genus</td>\n",
              "      <td>image.3.jpg</td>\n",
              "      <td>image.23.jpg</td>\n",
              "      <td>image.4.jpg</td>\n",
              "      <td>image.1.jpg</td>\n",
              "      <td>image.2.jpg</td>\n",
              "      <td>image.20.jpg</td>\n",
              "      <td>image.5.jpg</td>\n",
              "      <td>image.24.jpg</td>\n",
              "      <td>image.22.jpg</td>\n",
              "      <td>image.21.jpg</td>\n",
              "      <td>image.20.jpg</td>\n",
              "      <td>Old World finches; e.g. canaries and serins or...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>pegmatite</td>\n",
              "      <td>pegmatite igneous</td>\n",
              "      <td>image.41.jpg</td>\n",
              "      <td>image.39.jpg</td>\n",
              "      <td>image.42.jpg</td>\n",
              "      <td>image.43.jpg</td>\n",
              "      <td>image.40.jpg</td>\n",
              "      <td>image.44.jpg</td>\n",
              "      <td>image.37.jpg</td>\n",
              "      <td>image.38.jpg</td>\n",
              "      <td>image.36.jpg</td>\n",
              "      <td>image.35.jpg</td>\n",
              "      <td>image.35.jpg</td>\n",
              "      <td>produced under conditions involving intense he...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>bonxie</td>\n",
              "      <td>bonxie skua</td>\n",
              "      <td>image.3.jpg</td>\n",
              "      <td>image.77.jpg</td>\n",
              "      <td>image.78.jpg</td>\n",
              "      <td>image.4.jpg</td>\n",
              "      <td>image.1.jpg</td>\n",
              "      <td>image.2.jpg</td>\n",
              "      <td>image.5.jpg</td>\n",
              "      <td>image.79.jpg</td>\n",
              "      <td>image.76.jpg</td>\n",
              "      <td>image.75.jpg</td>\n",
              "      <td>image.75.jpg</td>\n",
              "      <td>gull-like jaeger of northern seas or gull-like...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ixia</td>\n",
              "      <td>ixia genus</td>\n",
              "      <td>image.90.jpg</td>\n",
              "      <td>image.3.jpg</td>\n",
              "      <td>image.91.jpg</td>\n",
              "      <td>image.4.jpg</td>\n",
              "      <td>image.92.jpg</td>\n",
              "      <td>image.1.jpg</td>\n",
              "      <td>image.2.jpg</td>\n",
              "      <td>image.94.jpg</td>\n",
              "      <td>image.93.jpg</td>\n",
              "      <td>image.5.jpg</td>\n",
              "      <td>image.90.jpg</td>\n",
              "      <td>a monocotyledonous genus of the family Iridace...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  target_word        full_phrase       image_0       image_1       image_2  \\\n",
              "0     moorhen   moorhen swamphen   image.3.jpg   image.8.jpg   image.4.jpg   \n",
              "1     serinus      serinus genus   image.3.jpg  image.23.jpg   image.4.jpg   \n",
              "2   pegmatite  pegmatite igneous  image.41.jpg  image.39.jpg  image.42.jpg   \n",
              "3      bonxie        bonxie skua   image.3.jpg  image.77.jpg  image.78.jpg   \n",
              "4        ixia         ixia genus  image.90.jpg   image.3.jpg  image.91.jpg   \n",
              "\n",
              "        image_3       image_4       image_5       image_6       image_7  \\\n",
              "0   image.1.jpg   image.2.jpg   image.0.jpg   image.5.jpg   image.6.jpg   \n",
              "1   image.1.jpg   image.2.jpg  image.20.jpg   image.5.jpg  image.24.jpg   \n",
              "2  image.43.jpg  image.40.jpg  image.44.jpg  image.37.jpg  image.38.jpg   \n",
              "3   image.4.jpg   image.1.jpg   image.2.jpg   image.5.jpg  image.79.jpg   \n",
              "4   image.4.jpg  image.92.jpg   image.1.jpg   image.2.jpg  image.94.jpg   \n",
              "\n",
              "        image_8       image_9   gold_images  \\\n",
              "0   image.7.jpg   image.9.jpg   image.0.jpg   \n",
              "1  image.22.jpg  image.21.jpg  image.20.jpg   \n",
              "2  image.36.jpg  image.35.jpg  image.35.jpg   \n",
              "3  image.76.jpg  image.75.jpg  image.75.jpg   \n",
              "4  image.93.jpg   image.5.jpg  image.90.jpg   \n",
              "\n",
              "                                              senses  \n",
              "0  black gallinule that inhabits ponds and lakes ...  \n",
              "1  Old World finches; e.g. canaries and serins or...  \n",
              "2  produced under conditions involving intense he...  \n",
              "3  gull-like jaeger of northern seas or gull-like...  \n",
              "4  a monocotyledonous genus of the family Iridace...  "
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset.head()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "c2781180",
      "metadata": {},
      "source": [
        "# Word2Vec model\n",
        "\n",
        "Reference (https://www.tensorflow.org/tutorials/text/word2vec)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "1714557c",
      "metadata": {},
      "outputs": [],
      "source": [
        "import io\n",
        "import re\n",
        "import string\n",
        "import tqdm\n",
        "\n",
        "from tensorflow.keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "702ef47b",
      "metadata": {},
      "outputs": [],
      "source": [
        "SEED = 42\n",
        "AUTOTUNE = tf.data.AUTOTUNE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "c4857343",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the vocabulary size and the number of words in a sequence.\n",
        "VOCAB_SIZE = 4096\n",
        "SEQUENCE_LENGTH = 10"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "5397de55",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generates skip-gram pairs with negative sampling for a list of sequences\n",
        "# (int-encoded sentences) based on window size, number of negative samples\n",
        "# and vocabulary size.\n",
        "def generate_training_data(sequences, window_size, num_ns, vocab_size, seed):\n",
        "  # Elements of each training example are appended to these lists.\n",
        "  targets, contexts, labels = [], [], []\n",
        "\n",
        "  # Build the sampling table for `vocab_size` tokens.\n",
        "  sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(vocab_size)\n",
        "\n",
        "  # Iterate over all sequences (sentences) in the dataset.\n",
        "  for sequence in tqdm.tqdm(sequences):\n",
        "\n",
        "    # Generate positive skip-gram pairs for a sequence (sentence).\n",
        "    positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n",
        "          sequence,\n",
        "          vocabulary_size=vocab_size,\n",
        "          sampling_table=sampling_table,\n",
        "          window_size=window_size,\n",
        "          negative_samples=0)\n",
        "\n",
        "    # Iterate over each positive skip-gram pair to produce training examples\n",
        "    # with a positive context word and negative samples.\n",
        "    for target_word, context_word in positive_skip_grams:\n",
        "      context_class = tf.expand_dims(\n",
        "          tf.constant([context_word], dtype=\"int64\"), 1)\n",
        "      negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n",
        "          true_classes=context_class,\n",
        "          num_true=1,\n",
        "          num_sampled=num_ns,\n",
        "          unique=True,\n",
        "          range_max=vocab_size,\n",
        "          seed=seed,\n",
        "          name=\"negative_sampling\")\n",
        "\n",
        "      # Build context and label vectors (for one target word)\n",
        "      context = tf.concat([tf.squeeze(context_class,1), negative_sampling_candidates], 0)\n",
        "      label = tf.constant([1] + [0]*num_ns, dtype=\"int64\")\n",
        "\n",
        "      # Append each element from the training example to global lists.\n",
        "      targets.append(target_word)\n",
        "      contexts.append(context)\n",
        "      labels.append(label)\n",
        "\n",
        "  return targets, contexts, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "37552ea9",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "11722"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(dataset) # Size of the dataset"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "184fd065",
      "metadata": {},
      "source": [
        "Reads the `full_phrase` and `senses` then combine them into `result_sense.txt` corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "2d30c527",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating the senses text files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 11722/11723 [00:01<00:00, 8669.78it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Combining senses text files into one...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 11722/11722 [00:00<00:00, 18361.15it/s]\n"
          ]
        }
      ],
      "source": [
        "import glob\n",
        "# +------------------------------------------------------------+\n",
        "# | had to do this hacky way to make jupyter run the for-loop  |\n",
        "# | probably without repeating the first index of the `dataset`|\n",
        "# +------------------------------------------------------------+\n",
        "list_index = []\n",
        "for index in range(len(dataset)):\n",
        "    if index % 1 == 0:\n",
        "        list_index.append(index)\n",
        "\n",
        "# adds the final index that is not divisible by the mod number\n",
        "if len(dataset) not in list_index:\n",
        "    list_index.append(len(dataset)) \n",
        "\n",
        "\n",
        "if os.path.isfile(path + \"result_senses.txt\") == False:\n",
        "    # i being the first index, y being the index after it\n",
        "    print(\"Creating the senses text files...\")\n",
        "    for i, y in zip(tqdm.tqdm(list_index), list_index[1:]):\n",
        "        file = open(path + \"senses%d.txt\"%y, \"w\")\n",
        "        dataset_senses = \"\"\n",
        "        for full_phrase, senses in zip(dataset.full_phrase[i:y], dataset.senses[i:y]):\n",
        "            dataset_senses +=  full_phrase + \" \" + senses + \"\\n\"\n",
        "            file.write(dataset_senses)\n",
        "        file.close()\n",
        "        del full_phrase, senses  # clears the memory to avoid memory leak\n",
        "    \n",
        "    # Reference (https://stackoverflow.com/a/17749339)\n",
        "    print(\"Combining senses text files into one...\")\n",
        "    senses_files = sorted(glob.glob(path + \"senses*.txt\"))\n",
        "    with open(path + \"result_senses.txt\", \"wb\") as outfile:\n",
        "        for f in tqdm.tqdm(senses_files):\n",
        "            with open(f, \"rb\") as infile:\n",
        "                outfile.write(infile.read())\n",
        "            os.remove(f)\n",
        "        \n",
        "else:\n",
        "    print(\"[result_senses.txt has already been created]\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "400670a0",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Metal device set to: Apple M1 Pro\n",
            "\n",
            "systemMemory: 16.00 GB\n",
            "maxCacheSize: 5.33 GB\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-03-18 17:14:49.926070: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:305] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
            "2023-03-18 17:14:49.926216: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:271] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
          ]
        }
      ],
      "source": [
        "text_ds = tf.data.TextLineDataset(path + \"result_senses.txt\").filter(lambda x: tf.cast(tf.strings.length(x), bool))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "902124a9",
      "metadata": {},
      "source": [
        "Vectorize sentences from the corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "f0fd2d81",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Now, create a custom standardization function to lowercase the text and\n",
        "# remove punctuation.\n",
        "def custom_standardization(input_data):\n",
        "  lowercase = tf.strings.lower(input_data)\n",
        "  return tf.strings.regex_replace(lowercase,\n",
        "                                  '[%s]' % re.escape(string.punctuation), '')\n",
        "\n",
        "# Use the `TextVectorization` layer to normalize, split, and map strings to\n",
        "# integers. Set the `output_sequence_length` length to pad all samples to the\n",
        "# same length.\n",
        "vectorize_layer = layers.TextVectorization(\n",
        "    standardize=custom_standardization,\n",
        "    max_tokens=VOCAB_SIZE,\n",
        "    output_mode='int',\n",
        "    output_sequence_length=SEQUENCE_LENGTH)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "bf333971",
      "metadata": {},
      "source": [
        "Call `TextVectorization.adapt` on the text dataset to create vocabulary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "4803bf7b",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-03-18 17:14:50.007099: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
            "2023-03-18 17:14:50.050361: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        }
      ],
      "source": [
        "vectorize_layer.adapt(text_ds.batch(1024))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "ca936130",
      "metadata": {},
      "source": [
        "Once the state of the layer has been adapted to represent the text corpus, the vocabulary can be accessed with `TextVectorization.get_vocabulary`. This function returns a list of all vocabulary tokens sorted (descending) by their frequency."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "6dc21115",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['', '[UNK]', 'or', 'a', 'of', 'the', 'and', 'in', 'to', 'an', 'that', 'for', 'by', 'with', 'something', 'as', 'one', 'is', 'group', 'genus']\n"
          ]
        }
      ],
      "source": [
        "# Save the created vocabulary for reference.\n",
        "inverse_vocab = vectorize_layer.get_vocabulary()\n",
        "print(inverse_vocab[:20])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "42447642",
      "metadata": {},
      "source": [
        "The `vectorize_layer` can now be used to generate vectors for each element in the `text_ds` (a `tf.data.Dataset`). Apply `Dataset.batch`, `Dataset.prefetch`, `Dataset.map`, and `Dataset.unbatch`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "7404fb0a",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Vectorize the data in text_ds.\n",
        "text_vector_ds = text_ds.batch(1024).prefetch(AUTOTUNE).map(vectorize_layer).unbatch()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "b2cc5602",
      "metadata": {},
      "source": [
        "Obtain sequences from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "de1d88ad",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "11722\n"
          ]
        }
      ],
      "source": [
        "sequences = list(text_vector_ds.as_numpy_iterator())\n",
        "print(len(sequences))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "daa703d4",
      "metadata": {},
      "source": [
        "Inspect a few examples from `sequences`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "f691e043",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[   1    1  332    1   10    1    1    6 3609    2] => ['[UNK]', '[UNK]', 'black', '[UNK]', 'that', '[UNK]', '[UNK]', 'and', 'lakes', 'or']\n",
            "[  1   1   3 102  25  17   3 231   4   1] => ['[UNK]', '[UNK]', 'a', 'criminal', 'who', 'is', 'a', 'member', 'of', '[UNK]']\n",
            "[  1  46   3  45  54  57  56   2 115  45] => ['[UNK]', 'family', 'a', 'social', 'unit', 'living', 'together', 'or', 'primary', 'social']\n",
            "[  1 733   1 733   1   1   7 220   2   1] => ['[UNK]', 'horse', '[UNK]', 'horse', '[UNK]', '[UNK]', 'in', 'size', 'or', '[UNK]']\n",
            "[   1    1    5  597    1   63    4    5 1993  161] => ['[UNK]', '[UNK]', 'the', 'fleshy', '[UNK]', 'part', 'of', 'the', 'external', 'human']\n"
          ]
        }
      ],
      "source": [
        "for seq in sequences[:5]:\n",
        "  print(f\"{seq} => {[inverse_vocab[i] for i in seq]}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "bbe4e753",
      "metadata": {},
      "source": [
        "Generate training examples from sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "2d151b2c",
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 11722/11722 [00:45<00:00, 259.52it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "targets.shape: (41461,)\n",
            "contexts.shape: (41461, 5)\n",
            "labels.shape: (41461, 5)\n"
          ]
        }
      ],
      "source": [
        "targets, contexts, labels = generate_training_data(\n",
        "    sequences=sequences,\n",
        "    window_size=2,\n",
        "    num_ns=4,\n",
        "    vocab_size=VOCAB_SIZE,\n",
        "    seed=SEED)\n",
        "\n",
        "targets = np.array(targets)\n",
        "contexts = np.array(contexts)\n",
        "labels = np.array(labels)\n",
        "\n",
        "print('\\n')\n",
        "print(f\"targets.shape: {targets.shape}\")\n",
        "print(f\"contexts.shape: {contexts.shape}\")\n",
        "print(f\"labels.shape: {labels.shape}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "cec6ba27",
      "metadata": {},
      "source": [
        "## Training of Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "bb1a33e5",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<BatchDataset shapes: (((1024,), (1024, 5)), (1024, 5)), types: ((tf.int64, tf.int64), tf.int64)>\n"
          ]
        }
      ],
      "source": [
        "BATCH_SIZE = 1024\n",
        "BUFFER_SIZE = 10000\n",
        "final_dataset = tf.data.Dataset.from_tensor_slices(((targets, contexts), labels))\n",
        "final_dataset = final_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n",
        "print(final_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "2cda96d8",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<PrefetchDataset shapes: (((1024,), (1024, 5)), (1024, 5)), types: ((tf.int64, tf.int64), tf.int64)>\n"
          ]
        }
      ],
      "source": [
        "final_dataset = final_dataset.cache().prefetch(buffer_size=AUTOTUNE)\n",
        "print(final_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "a7776f48",
      "metadata": {},
      "outputs": [],
      "source": [
        "num_ns = 4  # number of negative samples"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "1039c5c0",
      "metadata": {},
      "source": [
        "Subclassed word2vec model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "94d8d663",
      "metadata": {},
      "outputs": [],
      "source": [
        "class Word2Vec(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim):\n",
        "    super(Word2Vec, self).__init__()\n",
        "    self.target_embedding = layers.Embedding(vocab_size,\n",
        "                                      embedding_dim,\n",
        "                                      input_length=1,\n",
        "                                      name=\"w2v_embedding\")\n",
        "    self.context_embedding = layers.Embedding(vocab_size,\n",
        "                                       embedding_dim,\n",
        "                                       input_length=num_ns+1)\n",
        "\n",
        "  def call(self, pair):\n",
        "    target, context = pair\n",
        "    # target: (batch, dummy?)  # The dummy axis doesn't exist in TF2.7+\n",
        "    # context: (batch, context)\n",
        "    if len(target.shape) == 2:\n",
        "      target = tf.squeeze(target, axis=1)\n",
        "    # target: (batch,)\n",
        "    word_emb = self.target_embedding(target)\n",
        "    # word_emb: (batch, embed)\n",
        "    context_emb = self.context_embedding(context)\n",
        "    # context_emb: (batch, context, embed)\n",
        "    dots = tf.einsum('be,bce->bc', word_emb, context_emb)\n",
        "    # dots: (batch, context)\n",
        "    return dots"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "13e4c7eb",
      "metadata": {},
      "source": [
        "Define loss function and compile model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "d96f6dff",
      "metadata": {},
      "outputs": [],
      "source": [
        "embedding_dim = 128\n",
        "word2vec = Word2Vec(VOCAB_SIZE, embedding_dim)\n",
        "word2vec.compile(optimizer='adam',\n",
        "                 loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
        "                 metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "52062d69",
      "metadata": {},
      "outputs": [],
      "source": [
        "log_dir='logs/'\n",
        "if not os.path.exists(log_dir):\n",
        "    os.makedirs(log_dir)\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "37c31d21",
      "metadata": {},
      "source": [
        "Train the model on the `final_dataset` for some number of epochs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "8129b803",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-03-18 17:15:48.763380: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:112] Plugin optimizer for device_type GPU is enabled.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "40/40 [==============================] - 2s 29ms/step - loss: 1.6042 - accuracy: 0.3251\n",
            "Epoch 2/20\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 1.5674 - accuracy: 0.6737\n",
            "Epoch 3/20\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 1.4695 - accuracy: 0.6653\n",
            "Epoch 4/20\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 1.3264 - accuracy: 0.6245\n",
            "Epoch 5/20\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 1.2053 - accuracy: 0.6200\n",
            "Epoch 6/20\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 1.1116 - accuracy: 0.6389\n",
            "Epoch 7/20\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 1.0292 - accuracy: 0.6697\n",
            "Epoch 8/20\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.9531 - accuracy: 0.7028\n",
            "Epoch 9/20\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.8830 - accuracy: 0.7323\n",
            "Epoch 10/20\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.8189 - accuracy: 0.7576\n",
            "Epoch 11/20\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.7607 - accuracy: 0.7789\n",
            "Epoch 12/20\n",
            "40/40 [==============================] - 1s 20ms/step - loss: 0.7079 - accuracy: 0.7971\n",
            "Epoch 13/20\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.6601 - accuracy: 0.8143\n",
            "Epoch 14/20\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.6166 - accuracy: 0.8287\n",
            "Epoch 15/20\n",
            "40/40 [==============================] - 1s 24ms/step - loss: 0.5770 - accuracy: 0.8419\n",
            "Epoch 16/20\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.5409 - accuracy: 0.8539\n",
            "Epoch 17/20\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.5079 - accuracy: 0.8649\n",
            "Epoch 18/20\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.4777 - accuracy: 0.8760\n",
            "Epoch 19/20\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.4500 - accuracy: 0.8850\n",
            "Epoch 20/20\n",
            "40/40 [==============================] - 1s 21ms/step - loss: 0.4247 - accuracy: 0.8930\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x176ee1400>"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word2vec.fit(final_dataset, epochs=20, callbacks=[tensorboard_callback])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "15b37d2e",
      "metadata": {},
      "source": [
        "## Embedding lookup and analysis\n",
        "\n",
        "Reference (https://www.tensorflow.org/tensorboard/tensorboard_projector_plugin)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "b0604d3b",
      "metadata": {},
      "outputs": [],
      "source": [
        "from tensorboard.plugins import projector\n",
        "\n",
        "if (os.path.isfile(log_dir + \"vectors.tsv\") and os.path.isfile(log_dir + \"metadata.tsv\")) == False:\n",
        "  weights = word2vec.get_layer('w2v_embedding').get_weights()[0]\n",
        "  vocab = vectorize_layer.get_vocabulary()\n",
        "  out_v = io.open(log_dir + 'vectors.tsv', 'w', encoding='utf-8')\n",
        "  out_m = io.open(log_dir + 'metadata.tsv', 'w', encoding='utf-8')\n",
        "\n",
        "  for index, word in enumerate(vocab):\n",
        "    if index == 0:\n",
        "      continue  # skip 0, it's padding.\n",
        "    vec = weights[index]\n",
        "    out_v.write('\\t'.join([str(x) for x in vec]) + \"\\n\")\n",
        "    out_m.write(word + \"\\n\")\n",
        "  out_v.close()\n",
        "  out_m.close()\n",
        "\n",
        "else:\n",
        "   print(\"[vectors.csv and metadata.csv already exists]\")\n",
        "\n",
        "# Save the weights we want to analyze as a variable. Note that the first\n",
        "# value represents any unknown word, which is not in the metadata, here\n",
        "# we will remove this value.\n",
        "weights = tf.Variable(word2vec.layers[0].get_weights()[0][1:])\n",
        "# Create a checkpoint from embedding, the filename and key are the\n",
        "# name of the tensor.\n",
        "checkpoint = tf.train.Checkpoint(embedding=weights)\n",
        "checkpoint.save(os.path.join(log_dir, \"embedding.ckpt\"))\n",
        "\n",
        "\n",
        "# Set up config.\n",
        "config = projector.ProjectorConfig()\n",
        "embedding = config.embeddings.add()\n",
        "# The name of the tensor will be suffixed by `/.ATTRIBUTES/VARIABLE_VALUE`.\n",
        "embedding.tensor_name = \"embedding/.ATTRIBUTES/VARIABLE_VALUE\"\n",
        "embedding.metadata_path = 'metadata.tsv'\n",
        "projector.visualize_embeddings(log_dir, config)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "5331c7af",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "      <iframe id=\"tensorboard-frame-d7c04806d8aca3a3\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
              "      </iframe>\n",
              "      <script>\n",
              "        (function() {\n",
              "          const frame = document.getElementById(\"tensorboard-frame-d7c04806d8aca3a3\");\n",
              "          const url = new URL(\"http://localhost\");\n",
              "          const port = 6006;\n",
              "          if (port) {\n",
              "            url.port = port;\n",
              "          }\n",
              "          frame.src = url;\n",
              "        })();\n",
              "      </script>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Now run tensorboard against on log data we just saved.\n",
        "%tensorboard --logdir logs"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "dad450a28c894495c754ffb1489f7750013982b9a26900c90ef19258e6c32c78"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
